Introduction and Analysis of Sorting Algorithms


------------Selection Sort-----------
*Introduction: A simple sorting algorithm that repeatedly searches remaining items to find the least one and moves it to its final location[1], which mirrors the way we often sort items by hand.
*Algorithm Steps:
step 1: Go through the unsorted part of the array to find the smallest element (In the first run, sorted part's number of element is 0)
step 2: Swap the smallest element found in step 1 with the first element behind the sorted part
step 3: Move the boundary between the sorted part and the unsorted part by one position toward the end of the array
step 3: If the number of elements in the sorted part is not equal to the number of elements in the array, go back to step 1. Otherwise, the array is sorted
*Complexity Analysis: As selection sort does not take advantage of the array's distribution and always performs the same operations, the complexity remains the same in the best-case and worst-case scenarios. 
    Best-case time complexity: O(n^2)
    Average-case time complexity: O(n^2)
    Worst-case time complexity: O(n^2)

------------Insertion Sort------------
*Introduction: A simple sorting algorithm that sorts by repeatedly taking the next item and inserting it into the final data structure in its proper order with respect to items already inserted[2].
*Algorithm Steps:
step 1: Pick the first element (As there's just one element, the number of elements in the sorted part will be 1.)
step 2: Pick the first element behind the sorted part
step 3: Compare it with each element in the sorted part to find the target position
step 4: Insert the element into the sorted part at the position found in step 3
step 5: Move the boundary between sorted part and unsorted part by one position toward the end of array
step 6: If the number of sorted part's element is not equal to the number of element in the array, go back to step 2. Otherwise, the array is sorted.
*Complexity Analysis: 
    Best-case time complexity: O(n) - happens when the array is already sorted
    Average-case time complexity: O(n^2)
    Worst-case time complexity: O(n^2)
*Optimizations: When comparisons are expensive, we can use binary search instead of comparing each element to find the position in step 3. However, this would make the sort unstable when there are duplicate elements.

------------Bubble Sort------------
*Introduction:
*Algorithm Steps:
*Complexity Analysis:
*Optimizations:

------------Heap Sort------------
*Introduction:
*Algorithm Steps:
*Complexity Analysis:
*Optimizations:

------------Merge Sort------------
*Introduction: Merge sort is an algorithm that follows the divide-and-conquer method. Starting with the entire array A[1:n], it recurses down to smaller and smaller subarrays. The key operation of the merge sort algorithm occurs in the "combine" step, which merges two adjacent, sorted subarrays[3].
*Algorithm Steps:
step 1: If the input array has only 1 element, return that input array as sorted. If the input array has more than 1 element, continue to step 2.
step 2: Split the input array into 2 smaller arrays, the first subarray (subarray 1) takes the original array's first half number of elements, the second subarray (subarray 2) takes the remain elements in the input array.
step 3: Perform step 1-3 for each of the two subarrays as input arrays.
step 4: Compare the first untaken element of subarray 1 with the first untaken element of subarray 2, and add the smaller element to the input array to the first position of unsorted part. If either sub-array has no untaken element left, add the first untaken element of the other sub-array to the input array.
step 5: Increate the number of taken element of the sub-array that provided an element by 1, increase the number of sorted element in the input array by 1.
step 6: If the number of elements in the sorted part is not equal to the number of elements of the input array, go back to step 4. Otherwise, the input array is sorted.
*Complexity Analysis: Because merge sort splits the entire n-array to n 1-element arrays then merges them to sort, the complexity does not depend on the array's distribution.
    Best-case time complexity: O(nlog(n))
    Average-case time complexity: O(nlog(n))
    Worst-case time complexity: O(nlog(n))

------------Quick Sort------------
*Introduction:
*Algorithm Steps:
*Complexity Analysis:
*Optimizations:

------------Radix Sort------------
*Introduction:
*Algorithm Steps:
*Complexity Analysis:
*Optimizations:

------------Shaker Sort------------
*Introduction:
*Algorithm Steps:
*Complexity Analysis:
*Optimizations:

------------Shell sort------------
*Introduction:
*Algorithm Steps:
D1. [Loop on s.] Perform step D2 for s = t − 1, t − 2, . . ., 0; then
terminate the algorithm.
D2. [Loop on j.] Set h ← hs, and perform steps D3 through D6 for h
< j ≤ N. (We will use a straight insertion method to sort elements
that are h positions apart, so that Ki ≤ Ki+h for 1 ≤ i ≤ N − h.
Steps D3 through D6 are essentially the same as steps S2 through
S5, respectively, in Algorithm S.)
D3. [Set up i, K, R.] Set i ← j − h, K ← Kj, R ← Rj.
D4. [Compare K : Ki.] If K ≥ Ki, go to step D6.
D5. [Move Ri, decrease i.] Set Ri+h ← Ri, then i ← i − h. If i > 0, go
back to step D4.
D6. [R into Ri+h.] Set Ri+h ← R
*Complexity Analysis:
*Optimizations:

------------Counting Sort------------
*Introduction:
*Algorithm Steps:
*Complexity Analysis:
*Optimizations:

------------Flash Sort------------
*Introduction:
*Algorithm Steps:
*Complexity Analysis:
*Optimizations:


References:
[1]: Paul E. Black, "selection sort", in Dictionary of Algorithms and Data Structures [online], Paul E. Black, ed. 21 April 2022, https://www.nist.gov/dads/HTML/selectionSort.html. Accessed 26 June 2024.
[2]: Paul E. Black, "insertion sort", in Dictionary of Algorithms and Data Structures [online], Paul E. Black, ed. 6 April 2023,https://www.nist.gov/dads/HTML/insertionSort.html. Accessed 26 June 2024.
[3]: Cormen, T.H., Leiserson, C.E., Rivest, R.L. and Stein, C., 2022. Introduction to Algorithms. 4th ed. Cambridge, MA: MIT Press, pp. 35-36.